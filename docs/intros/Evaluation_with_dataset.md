
# Datasets & Evaluation 컨셉 가이드

LLM 어플리케이션을 평가하기 위한 데이터셋과 평가 방법 입니다.
데이터셋을 준비해두고, LangSmith 에 적재해둔 다음 Evaluator 에 보내줍니다.
Evaluator는 LLM 어플리케이션의 결과와 데이터에 준비된 결과를 보고 평가합니다.
여기서 Dataset 의 Output (정답) 은 필수 사항이 아닙니다.
정답이 있으면 좋겠지만, 없어도 평가를 할수는 있죠.

![](rsc/dataset_evaluation_1.png)



## Datasets

LangSmith 에서는 주요한 데이터셋을 다룰 수 있습니다.
단순 저장소이기 때문에 "이걸 왜 설명하지?" 라고 하실 수 있겠지만,
Tracing (추적) 이나, Evaluation (평가) 기능과 연동되어 동작하기 때문에 매우 유용합니다.

### 생성 방법에 따른 데이터 분류

데이터셋의 생성은 다음과 같은 방법으로 할 수 있습니다.
- 연구/개발자가 직접 작성 또는 선정한 데이터
	- Input 과 예상 Output을 직접 작성합니다. 문제집과 정답이죠. 수십개 수준정도로 데이터의 양이 작더라도 기준이 되는 데이터셋이기 때문에 중요합니다.
- 로깅된 데이터
	- LLM 어플리케이션이 서비스가 시작되었다면, 사용자의 tracing 결과들이 로그가 되어 데이터셋으로 편입될 수 있습니다. 실제 사용 예시이고, 사용자 피드백이 같이 있다면 더 가치있는 데이터가 됩니다.
- 합성 데이터
	- LLM 어플리케이션을 이용해서 직접 생성해낼 수 도 있습니다. 사람이 직접 검토하지 않는다면, 데이터가 저품질일 위험성이 있지만, 자동 생성되어서 양을 많이 늘릴 수 있습니다.

LangSmith 플랫폼은 위 3가지 방법으로 생성되는 데이터를 모두 쉽게 데이터셋에 추가할 수 있게 지원합니다.

### LangSmith 의 데이터 타입

LangSmith 에서는 아래 3가지 타입으로 데이터가 구분됩니다.
- kv (key-value)
	- 일반적인 딕셔너리 형태와 같습니다. 가장 범용적이고, 다양한 evaluation 시나리오를 커버합니다.
	- 기본 타입이기도하고, 그냥 kv 타입 사용하면 웬만하면 됩니다.
- llm (large language model)
	- "completion" 스타일의 llm 평가를 위해 사용됩니다.
- chat
	- 채팅 스타일로 챗봇과 같은 대화 스타일 평가를 위해 사용됩니다.

### 데이터 셋 나누기

용도에 따라 데이터셋을 나눌 수 있습니다.  
작고 빠른 테스트용, 풀 테스트용 과 같이 테스트 규모에 따라서 나눌 수 있습니다.  
팩트 체크용 이라던가, 의견 제시용 이라던가, 다양한 task 를 수행해야하는 경우 task 별로 나누기도 합니다.  


## Evaluation (평가)

TBD.